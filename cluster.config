
akka {


persistence{
journal {
sql-server {
# qualified type name of the SQL Server persistence journal actor
class = "Akka.Persistence.SqlServer.Journal.SqlServerJournal, Akka.Persistence.SqlServer"

# dispatcher used to drive journal actor
plugin-dispatcher = "akka.actor.default-dispatcher"

# connection string used for database access
connection-string = "Server=API-LT-022\\SQLEXPRESS;Database=akkaTest;Trusted_Connection=True;"

# default SQL commands timeout
connection-timeout = 30s

# SQL server schema name to table corresponding with persistent journal
schema-name = dbo

# SQL server table corresponding with persistent journal
table-name = EventJournal

# should corresponding journal table be initialized automatically
auto-initialize = off

# timestamp provider used for generation of journal entries timestamps
timestamp-provider = "Akka.Persistence.Sql.Common.Journal.DefaultTimestampProvider, Akka.Persistence.Sql.Common"

# metadata table
metadata-table-name = Metadata
}
}

snapshot-store {
sql-server {

# qualified type name of the SQL Server persistence journal actor
class = "Akka.Persistence.SqlServer.Snapshot.SqlServerSnapshotStore, Akka.Persistence.SqlServer"

# dispatcher used to drive journal actor
plugin-dispatcher = ""akka.actor.default-dispatcher""

# connection string used for database access
connection-string = "Server=API-LT-022\\SQLEXPRESS;Database=akkaTest;Trusted_Connection=True;"

# default SQL commands timeout
connection-timeout = 30s

# SQL server schema name to table corresponding with persistent journal
schema-name = dbo

# SQL server table corresponding with persistent journal
table-name = SnapshotStore

# should corresponding journal table be initialized automatically
auto-initialize = off
}
}
}


stdout-loglevel = DEBUG
loglevel = DEBUG
akka.actor.serialize-messages = on
loggers=["Akka.Logger.Serilog.SerilogLogger, Akka.Logger.Serilog"]
actor {
provider = "Akka.Cluster.ClusterActorRefProvider, Akka.Cluster"
DEBUG {
log-config-on-start = off
receive = off
autoreceive = on
lifecycle = on
event-stream = on
unhandled = on
stdout-loglevel = DEBUG
log-received-messages = off
}
}

remote {
helios.tcp {
port = 8091
hostname = __hostname__
}
}

cluster {
seed-nodes = ["akka.tcp://ClusterSystem@__hostname__:8091"]
roles = [master]
}
}

my-dispatcher {
type = TaskDispatcher
throughput = 1
throughput-deadline-time = 0ms
}

application {
environment = app
#environment = devMock

devMock {
useFixedConfigFile = true
FixedConfigClassName = DevMockConfig
}

app {
useFixedConfigFile = false

ApiEndPoint = "http://freegeek.azurewebsites.net/api/shop"

Environment = "Prod"

CsvLineValidationRegex = "^(\\d+)\\s?,([^,]*?),([^,]*?),(\\d+\\/\\d+\\/\\d+[^,]\\s*?)$"
HeaderValidationRegex = "^data id,shop name,city,created on$"
DateValidationRegex = "(\\d+?\\/\\d+?\\/\\d+?[^,]\\s*?)$"


HttpTimeoutInMiniseconds = 20000
HttpRetries = 3
WorkerIdleTime = 2000
InitialApiErrorThresholdToShutdownSystem = 3

OutputFileHeader = "data id,sale"
StopIfDestinationFileExists = false
WriteWaitCycleInMiniseconds = 1000

ReadLinesBatchSize = 100
InternalChunkSize = 20
DataDistributorActorCount = 2
LoadFactor = 250
RemoteHost1=axu
HowToScale = 4
CrawlerActorsCount = 8
WaitForClusterStartMessage = true
}
}
